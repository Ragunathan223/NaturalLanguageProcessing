{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18a1829c",
   "metadata": {},
   "source": [
    "# 2. Develop python code to extract data from a HTML page from the web using Beautiful Soup library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afada841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\ragunathan e s\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ragunathan e s\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ragunathan e s\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ragunathan e s\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82ce9395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3cf85af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate Heading and Non-heading\n",
    "\n",
    "# Read the HTML file\n",
    "with open('SourceCodeDictionaryData.html', 'r', encoding='utf-8') as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "# Parse the HTML using BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "def process_batch(batch_elements):\n",
    "    headings = []\n",
    "    non_headings = []\n",
    "\n",
    "    for element in batch_elements:\n",
    "        # Check if the element is in bold\n",
    "        if element.find('b') or element.find('strong'):\n",
    "            # Extract heading and the following text\n",
    "            heading = element.get_text().strip()\n",
    "            text = ''\n",
    "            for sibling in element.find_next_siblings():\n",
    "                if sibling.name and sibling.name.startswith('h'):\n",
    "                    break\n",
    "                text += sibling.get_text()\n",
    "            headings.append(heading)\n",
    "            non_headings.append(text.strip())\n",
    "\n",
    "    return headings, non_headings\n",
    "\n",
    "batch_size = 50  # Adjust this based on your memory constraints\n",
    "num_elements = len(soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6']))\n",
    "\n",
    "headings = []\n",
    "non_headings = []\n",
    "\n",
    "for start_idx in range(0, num_elements, batch_size):\n",
    "    end_idx = min(start_idx + batch_size, num_elements)\n",
    "    batch_elements = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])[start_idx:end_idx]\n",
    "\n",
    "    batch_headings, batch_non_headings = process_batch(batch_elements)\n",
    "    headings.extend(batch_headings)\n",
    "    non_headings.extend(batch_non_headings)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {'Headings': headings, 'Non-Headings': non_headings}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9c7a12",
   "metadata": {},
   "source": [
    "# 1. Develop python code to read data from a PDF file using PyPDF2 library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d28ea0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "     -------------------------------------- 232.6/232.6 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in c:\\users\\ragunathan e s\\anaconda3\\lib\\site-packages (from PyPDF2) (4.7.1)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ragunathan e s\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ragunathan e s\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ae52e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a857967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfFileReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d705ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = open(\"D:\\Research Methodology\\Sem-1 Churn prediction\\Customer Churn prediction in ECommerce Sector.pdf\",\"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd9d68fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdfreader = PyPDF2.PdfReader(pdf)\n",
    "len(pdfreader.pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ace09eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rochester Institute of T echnology Rochester Institute of T echnology \\nRIT Scholar W orks RIT Scholar W orks \\nTheses \\n5-2022 \\nCust omer Churn pr ediction in ECommer ce Sect or Cust omer Churn pr ediction in ECommer ce Sect or \\nAbdulr ahman Alshamsi \\naya8777@rit.edu \\nFollow this and additional works at: https:/ /scholar works.rit.edu/theses \\nRecommended Citation Recommended Citation \\nAlshamsi, Abdulr ahman, \"Cust omer Churn pr ediction in ECommer ce Sect or\" (2022). Thesis. Rochester \\nInstitute of T echnology . Accessed fr om \\nThis Master \\'s Project is br ought t o you for fr ee and open access b y RIT Scholar W orks. It has been accepted for \\ninclusion in Theses b y an authoriz ed administr ator of RI T Scholar W orks. F or mor e information, please contact \\nritscholar works@rit.edu . '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = pdfreader.pages[0]  # first page\n",
    "page.extract_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0974e7b9",
   "metadata": {},
   "source": [
    "# SELF-LEARN\n",
    "#3. Develop python code to extract data from a word file using docx library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48fa126d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python_docx-1.0.1-py3-none-any.whl (237 kB)\n",
      "     -------------------------------------- 237.4/237.4 kB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\ragunathan e s\\anaconda3\\lib\\site-packages (from python-docx) (4.8.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ragunathan e s\\anaconda3\\lib\\site-packages (from python-docx) (4.7.1)\n",
      "Installing collected packages: python-docx\n",
      "Successfully installed python-docx-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ragunathan e s\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ragunathan e s\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b31cb748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9062228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Word document\n",
    "doc = docx.Document(\"D:\\Downloads\\Sem-1\\Shapiro wilk test.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77aa2592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a variable to store the extracted text\n",
    "extracted_text = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b078fcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the paragraphs in the document and extract text\n",
    "for paragraph in doc.paragraphs:\n",
    "    extracted_text.append(paragraph.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "265eeacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normality test\n",
      "# loading the package\n",
      "library(\"dplyr\")\n",
      "## \n",
      "## Attaching package: 'dplyr'\n",
      "## The following objects are masked from 'package:stats':\n",
      "## \n",
      "##     filter, lag\n",
      "## The following objects are masked from 'package:base':\n",
      "## \n",
      "##     intersect, setdiff, setequal, union\n",
      "# Using the ToothGrowth package\n",
      "# loading the data set\n",
      "my_data <- ToothGrowth\n",
      "  \n",
      "# Using the set.seed() \n",
      "# for random number generation\n",
      "set.seed(1234)\n",
      "  \n",
      "# Using the sample_n() \n",
      "# for random sample of 10 rows\n",
      "dplyr::sample_n(my_data, 10)\n",
      "##     len supp dose\n",
      "## 1  21.5   VC  2.0\n",
      "## 2  17.3   VC  1.0\n",
      "## 3  27.3   OJ  2.0\n",
      "## 4  18.5   VC  2.0\n",
      "## 5   8.2   OJ  0.5\n",
      "## 6  26.4   OJ  1.0\n",
      "## 7  25.8   OJ  1.0\n",
      "## 8   5.2   VC  0.5\n",
      "## 9   6.4   VC  0.5\n",
      "## 10  9.4   OJ  0.5\n",
      "# Using the shapiro.test() to check\n",
      "# for normality based \n",
      "# on the len parameter\n",
      "shapiro.test(my_data$len)\n",
      "## \n",
      "##  Shapiro-Wilk normality test\n",
      "## \n",
      "## data:  my_data$len\n",
      "## W = 0.96743, p-value = 0.1091\n",
      "# Using the shapiro.test() to check\n",
      "# for normality based \n",
      "# on the len parameter\n",
      "shapiro.test(my_data$len)\n",
      "## \n",
      "##  Shapiro-Wilk normality test\n",
      "## \n",
      "## data:  my_data$len\n",
      "## W = 0.96743, p-value = 0.1091\n",
      "The p-value is greater than 0.05. Hence the distribution of the given data is not different from normal distribution.\n"
     ]
    }
   ],
   "source": [
    "# Print or process the extracted text as needed\n",
    "for text in extracted_text:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98607313",
   "metadata": {},
   "source": [
    "# 4. Develop python code to extract data from a JSON object using json library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "293a4368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "014ca70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_str = '{\"name\": \"Ragu\", \"age\": 22, \"city\": \"New York\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "940e1a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b05088eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Ragu\n",
      "Age: 22\n",
      "City: New York\n"
     ]
    }
   ],
   "source": [
    "name = data[\"name\"]\n",
    "age = data[\"age\"]\n",
    "city = data[\"city\"]\n",
    "\n",
    "print(\"Name:\", name)\n",
    "print(\"Age:\", age)\n",
    "print(\"City:\", city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1686dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
